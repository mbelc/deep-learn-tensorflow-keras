{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gqfXHGnDlVUE"
   },
   "source": [
    
    "# References\n",
    "\n",
    "Credit: codes developed in this project inspired by the following references:\n",
    "\n",
    "\\[2\\] https://www.tensorflow.org/tutorials/keras/classification\n",
    "\n",
    "\\[3\\] https://medium.com/analytics-vidhya/artificial-neural-network-ann-with-keras-simplified-use-case-if-student-pass-the-exam-code-949ddb2a9c91\n",
    "\n",
    "\\[4\\] https://machinelearningmastery.com/use-keras-deep-learning-models-scikit-learn-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FbVhjPpzn6BM"
   },
   "source": [
    "# Packages\n",
    "\n",
    "This tutorial uses [tensorflow.keras](https://www.tensorflow.org/guide/keras), a high-level API to build and train neural networks (NN). The developed NN is used to classify images of handwritten digits from 0 to 9 in the MNIST dataset. The required packages are imported below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dzLKpmZICaWN"
   },
   "outputs": [],
   "source": [
    "# pyplot to plot figures\n",
    "import matplotlib.pyplot as plt\n",
    "# numpy for algebraic operations on arrays\n",
    "import numpy as np\n",
    "# tensorflow API as tf\n",
    "import tensorflow as tf\n",
    "# tf.keras API for NN\n",
    "from tensorflow import keras\n",
    "# plot_model to visualize the built NN\n",
    "from tensorflow.keras.utils import plot_model\n",
    "# KerasClassifier to construct a NN model\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "# cross_val_score to evaluate NN model accuracy\n",
    "# GridSearchCV to fine-tune NN model from a list of parameters\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ElvmxvtA_Ivv"
   },
   "source": [
    "# Test 1: Loading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DLdCchMdCaWQ"
   },
   "source": [
    "This tutorial uses the [MNIST](http://yann.lecun.com/exdb/mnist/) dataset, which fits multiple regression and classification techniques. The dataset contains images of handwritten digits \\{0, 1, 2, ..., 9\\}, each in a format of 28 by 28 pixels, with pixel values ranging from 0 to 255. The dataset also contains a label for each image; the label is an integer in \\{0,1,2,...,9\\}. The dataset contains 60,000 training images and 10,000 testing images of individual digits labeled according to 10 classes of labels \\{0, 1, 2, ..., 9\\}. The training images and labels allow training a neural network (NN) and the testing images and labels allow evaluating the network's accuracy in classifying previously unseen images. To import and load the MNIST dataset so it can be used in `tf.keras`, function `load_data` is used to load the dataset directly from `TensorFlow`, which returns 4 `NumPy` arrays: `X_train` images with `y_train` labels for the training set, and `X_test` images with `y_test` labels for the testing set. The dimension of these arrays are confirmed by the below code snippets, which show 60,000 elements in `X_train` (and `y_train`), and 10,000 in `X_test` (and `y_test`). The pixel values are scaled down from \\[0,255\\] range to the standardized \\[0,1\\] range, which is done by dividing over the max value of 255. An image of a digit before and after scaling is shown below to confirm the data was scaled.\n",
    "\n",
    "K-fold cross-validation (CV) is used to test a regression or classification algorithm properly, and consists in splitting the training dataset into K-folds, training on K-1 of them and validating on the remaining fold, and switching the validation fold K times. The resulting mean error is a less-biased metric of the performance of the algorithm on the training dataset. To create cross-validation folds, a method from sklearn called `sklearn.model_selection.cross_val_score` is used to split the dataset, call the neural network constructor by argument `estimator`, specify the desired number of folds by argument `cv`, specify the training data and labels by arguments `X` and `y`, and finally perform cross-validation. Note that full descriptions of the neural network object `neurnet_classifier` and Keras constructor `KerasClassifier` will be discussed in the upcoming sections, as this section solely focuses on how to perform cross validation. The K-fold cross validation choose a number of folds `cv` equal to 5, which results in an accuracy for each run of the cross validation and a mean accuracy for the total cross validation such as shown by the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3308,
     "status": "ok",
     "timestamp": 1585957532368,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "7MqDQO0KCaWS",
    "outputId": "34bb99f1-6bd6-486d-d2d9-2560dc56a0b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# import mnist dataset from tf.keras\n",
    "data = keras.datasets.mnist\n",
    "# load mnist dataset into separate training images/labels and testing images/labels\n",
    "(X_train,y_train),(X_test,y_test) = data.load_data()\n",
    "# list the classes of labels, i.e. digits 0,1,2,3,4,5,6,7,8,9\n",
    "classes = range(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 91
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3301,
     "status": "ok",
     "timestamp": 1585957532368,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "zW5k_xz1CaWX",
    "outputId": "7f99ac87-7700-449b-c464-38f3df9a4d1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train dimensions: (60000, 28, 28)\n",
      "y_train elements: 60000\n",
      "X_test dimensions: (10000, 28, 28)\n",
      "y_test elements 10000\n"
     ]
    }
   ],
   "source": [
    "# check the dimensions of each array:\n",
    "# X_train: 60,000 images, each represented as 28 x 28 pixels\n",
    "print('X_train dimensions:', X_train.shape)\n",
    "# y_train: 60,000 labels\n",
    "print('y_train elements:', len(y_train))\n",
    "# X_test: 10,000 images, each represented as 28 x 28 pixels\n",
    "print('X_test dimensions:', X_test.shape)\n",
    "# y_test: 60,000 labels\n",
    "print('y_test elements:', len(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3295,
     "status": "ok",
     "timestamp": 1585957532368,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "m4VEw8Ud9Quh",
    "outputId": "d0d7d496-dd97-4daf-8fcc-9733db69006a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD4CAYAAACE9dGgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a single image from X_train\n",
    "# note that pixel values on the plot range from 0 to 255\n",
    "plt.figure()\n",
    "plt.imshow(X_train[2])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bW5WzIPlCaWv"
   },
   "outputs": [],
   "source": [
    "# scale data to [0,1] intervals by dividing each pixel value over 255\n",
    "X_train = (1.0/255.0) * X_train\n",
    "X_test  = (1.0/255.0) * X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3288,
     "status": "ok",
     "timestamp": 1585957532370,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "oZTImqg_CaW1",
    "outputId": "815a9e2c-6994-4b6b-924d-3f5b313dcb74"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAS4AAAD8CAYAAADJwUnTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrohonSSuiGidJK6IaJ0krohonf8PhdRJjwFnmW4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot a single image from X_train\n",
    "# note that pixel values on the plot now range from 0 to 1\n",
    "plt.figure()\n",
    "plt.imshow(X_train[2])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23047,
     "status": "ok",
     "timestamp": 1585957552134,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "lRdP69trPzgg",
    "outputId": "1ef21b7b-b317-4304-960d-3c096fc855c6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8650 - acc: 0.7423\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6267 - acc: 0.8832\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5878 - acc: 0.9018\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5690 - acc: 0.9115\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5569 - acc: 0.9173\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5477 - acc: 0.9236\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5407 - acc: 0.9287\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5349 - acc: 0.9325\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5300 - acc: 0.9361\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5258 - acc: 0.9392\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5255 - acc: 0.9414\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.8605 - acc: 0.7419\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6307 - acc: 0.8785\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5890 - acc: 0.9010\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5690 - acc: 0.9107\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5561 - acc: 0.9181\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5467 - acc: 0.9245\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.5394 - acc: 0.9287\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5337 - acc: 0.9329\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5289 - acc: 0.9377\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5250 - acc: 0.9406\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5310 - acc: 0.9353\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8429 - acc: 0.7549\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6239 - acc: 0.8825\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.5862 - acc: 0.9035\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5668 - acc: 0.9138\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5539 - acc: 0.9224\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5446 - acc: 0.9278\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5376 - acc: 0.9320\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5320 - acc: 0.9358\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 4ms/step - loss: 1.5274 - acc: 0.9397\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5235 - acc: 0.9426\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5284 - acc: 0.9363\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8713 - acc: 0.7221\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6284 - acc: 0.8766\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5884 - acc: 0.9012\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5687 - acc: 0.9129\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5562 - acc: 0.9209\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5469 - acc: 0.9262\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5398 - acc: 0.9313\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5341 - acc: 0.9351\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5293 - acc: 0.9382\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5253 - acc: 0.9413\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5334 - acc: 0.9313\n",
      "Epoch 1/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.8693 - acc: 0.7477\n",
      "Epoch 2/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.6291 - acc: 0.8794\n",
      "Epoch 3/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5877 - acc: 0.9017\n",
      "Epoch 4/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5675 - acc: 0.9127\n",
      "Epoch 5/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5544 - acc: 0.9196\n",
      "Epoch 6/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5449 - acc: 0.9268\n",
      "Epoch 7/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5376 - acc: 0.9313\n",
      "Epoch 8/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5318 - acc: 0.9352\n",
      "Epoch 9/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5270 - acc: 0.9392\n",
      "Epoch 10/10\n",
      "48/48 [==============================] - 0s 3ms/step - loss: 1.5229 - acc: 0.9422\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.5223 - acc: 0.9435\n"
     ]
    }
   ],
   "source": [
    "# Showing how to create cross-validation folds,\n",
    "# so that the algorithm can be tested properly\n",
    "#\n",
    "def neurnet_classifier():\n",
    "    # create model with each input being flattened\n",
    "    # sequential model is used to indicate the model has a linear stack of layers\n",
    "    # flatten is used to flatten the 28x28 input to 1x784 input\n",
    "    # dense layers are used to have fully interconnected neurons, allowing faster learning\n",
    "    # the number of neurons at the output layer must be equal to the number of classes (10)\n",
    "    # the relu activation function is chosen for the hidden layer because\n",
    "    # it avoids the saturation of its gradient, thus accelerating the convergence of \n",
    "    # gradient descent compared to other activation functions such as sigmoid / tanh\n",
    "    # the sigmoid activation function is chosen to smoothen the output to nearest\n",
    "    # value of either 0 (image not in class) or 1 (image in class)\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "    ])\n",
    "    # compile model that compares performance using accuracy as a metric, \n",
    "    # an optimizer based on the gradient descent algorithm such as adam, and \n",
    "    # a sparse categorical cross entropy which computes the crossentropy loss \n",
    "    # between the predictions and true labels, and is specifically designed for \n",
    "    # multi-class problems. from_logits indicates whether the prediction is a logits tensor.\n",
    "    # Using from_logits=True is more numerically stable according to documentation.\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "#\n",
    "# number of epochs\n",
    "n_epochs   = 10\n",
    "# number of datapoints propagated through the NN to train it each time\n",
    "n_batchsz  = 1000\n",
    "# number of cross validation folds\n",
    "n_cvfolds  = 5\n",
    "# construct a NN classifier using Keras constructor and calling the building function above\n",
    "cf         = KerasClassifier(build_fn=neurnet_classifier, batch_size=n_batchsz, epochs=n_epochs)\n",
    "# perform K-fold cross validation on training data/labels to return the list of accuracies\n",
    "accuracies = cross_val_score(estimator=cf, X=X_train, y=y_train, cv=n_cvfolds)\n",
    "# cross validation (CV) mean accuracy\n",
    "acc_mean   = accuracies.mean()\n",
    "# after cv is run iteratively on a list of values for a certain parameter, the\n",
    "# value resulting in highest mean accuracy (i.e. lowest mean error) is chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23041,
     "status": "ok",
     "timestamp": 1585957552135,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "zU1oeyAfHwj8",
    "outputId": "a770b6e1-c044-4d65-98e2-3349dfd25c31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv accuracies:  [0.94141668 0.93533331 0.93633336 0.93133336 0.94349998]\n",
      "mean of cv accuracies: 93.76%\n"
     ]
    }
   ],
   "source": [
    "# obtained cv accuracies\n",
    "print('cv accuracies: ', accuracies)\n",
    "# cv mean accuracy\n",
    "print('mean of cv accuracies: {0:.2f}%'.format(100*acc_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sHTVC0Jd_JNY"
   },
   "source": [
    "# Test 2: Creating a keras model (a simple network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "59veuiEZCaW4"
   },
   "source": [
    "A Keras model is used to build the neural network, which consists of a set of layers chained one after the other. The neurons in these layers are connected to each other using weighted links, and these weights are adjusted during the training by learning the representation of the training data that propagates throughout the NN.\n",
    "\n",
    "`tf.keras.Sequential` is used to model the neural network as a linear stack of layers. `keras.layers.Flatten` is used to flatten the input images of shape 28x28 to a shape of 1x784. `tf.keras.layers.Dense` is used to build fully interconnected layers in the NN, because they allow faster learning by the NN. The relu activation function is chosen for the hidden layer of size 128 because it avoids the saturation of its gradient, thus accelerating the convergence of gradient descent compared to other activation functions such as tanh and sigmoid. The number of neurons at the output layer must be equal to the total number of classes (10), and the sigmoid activation function is chosen to generate a smoothened probability in \\[0,1\\] interval, which can be converted to a crisp value of 0 if the probability is less than 1/2 to indicate that the image is not in the specified class, or otherwise converted to 1 to indicate that the image is in the specified class.\n",
    "\n",
    "A summary description table of the NN model is generated using `model.summary()`, and a figure of the NN model is illustrated by calling `tf.keras.utils.plot_model` and saved to a local *.png file. The summary and figure confirm the description of the NN model given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9ODch-OFCaW4"
   },
   "outputs": [],
   "source": [
    "# create model with each input being flattened\n",
    "# sequential model is used to indicate the model has a linear stack of layers\n",
    "# flatten is used to flatten the 28x28 input to 1x784 input\n",
    "# dense layers are used to have fully interconnected neurons, allowing faster learning\n",
    "# the number of neurons at the output layer must be equal to the number of classes (10)\n",
    "# the relu activation function is chosen for the hidden layer because\n",
    "# it avoids the saturation of its gradient, thus accelerating the convergence of \n",
    "# gradient descent compared to other activation functions such as sigmoid / tanh\n",
    "# the sigmoid activation function is chosen to smoothen the output to nearest\n",
    "# value of either 0 (image not in class) or 1 (image in class)\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 647
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23035,
     "status": "ok",
     "timestamp": 1585957552137,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "xJwP8LiINFkd",
    "outputId": "1aa03315-4e21-4f4c-9b5f-c354b586e1ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_5 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 128)               100480    \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPUAAAFgCAIAAADsD6h2AAAABmJLR0QA/wD/AP+gvaeTAAAgAElE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\ncPY/AH6hKl+7mHQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print a summary for the NN's model\n",
    "print(model.summary())\n",
    "# show a figure of the NN\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KGS6DWB8_Jnc"
   },
   "source": [
    "# Test 3: Compiling the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PU6wgNe-xNr_"
   },
   "source": [
    "The NN model must be compiled next before it is ready for the training phase. This is accomplished by using `model.compile` method in `tf.keras` with three parameters:\n",
    "\n",
    "`metrics` to specify the metric used to evaluate the model's performance, which in this case corresponds to accuracy using value `acc`. Accuracy is chosen to reflect the percentage of images that are correctly classified. Other choices could be made for `metrics` including the mean square error using value `mse`, or other metrics such as `binary_accuracy`, `categorical_accuracy`, `sparse_categorical_accuracy`, `top_k_categorical_accuracy`, `sparse_top_k_categorical_accuracy`, `cosine_proximity`.\n",
    "\n",
    "`loss` to measure the model's accuracy between the predicted labels and the true labels during training. This `loss` function is minimized to drive the model towards a local and possibly global optimum. Loss class `SparseCategoricalCrossentropy` is chosen to compute the cross-entropy loss between the true labels and predictions. This loss function is chosen because it is specifically suitable for multi-class problems. The argument `from_logits` indicates whether the predicted label is a [logits](https://developers.google.com/machine-learning/glossary#logits) tensor. Using `from_logits=True` is more numerically stable according to `tf.keras` documentation. Other choices could be made for `loss` including  `BinaryCrossentropy`, `CategoricalCrossentropy`, `CategoricalHinge`, `CosineSimilarity`, `Hinge`, `Huber`, `KLDivergence`, `LogCosh`, `MeanAbsoluteError`, `MeanAbsolutePercentageError`, `MeanSquaredError`, `MeanSquaredLogarithmicError`, `Poisson`, `Reduction`, `SquaredHinge`, and each of these options implements a standard loss function with the same name that evaluates the loss between the predictions and the true labels.\n",
    "\n",
    "`optimizer` to specify an update policy for the model's parameters based on the loss function values and on the data propagated throughout the NN. Optimizer class `Adam` that implements the Adam algorithm is chosen because this algorithm can handle sparse gradients on noisy data, which is the case in handwritten digits. Other choices could be made for `optimizer` including `Adadelta`, `Adagrad`, `Adamax`, `Ftrl`, `Nadam`, `RMSprop`, `SGD`, and each of these options implements a standard optimization algorithm with the same name, including gradient descent, stochastic optimization, and momentum optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Lhan11blCaW7"
   },
   "outputs": [],
   "source": [
    "# compile model that compares performance using accuracy as a metric, \n",
    "# an optimizer based on the gradient descent algorithm such as adam, and \n",
    "# a sparse categorical cross entropy which computes the crossentropy loss \n",
    "# between the predictions and true labels, and is specifically designed for \n",
    "# multi-class problems. from_logits indicates whether the prediction is a logits tensor.\n",
    "# Using from_logits=True is more numerically stable according to documentation.\n",
    "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R5bCBaaq_KqQ"
   },
   "source": [
    "# Test 4: Fitting the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKF6uW-BCaW-"
   },
   "source": [
    "Fitting the neural network model is performed by feeding the training data `X_train` and training labels `y_train` to the model using `model.fit` method. The number of epochs is specified using argument `epochs` with a value of 10, which was chosen to obtain a good accuracy. The number of epochs indicates how many times the algorithm should repeatedly go through the training data. The model then learns the representations of the training data and adjusts the NN weights accordingly. The training loss and accuracy metrics resulting from training on `X_train` are displayed by the below code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 406
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58726,
     "status": "ok",
     "timestamp": 1585957587837,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "xvwvpA64CaW_",
    "outputId": "0cf5e35a-e692-40d7-a48b-f0d2d3a0f88e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5697 - acc: 0.9089\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.5116 - acc: 0.9502\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4983 - acc: 0.9632\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4911 - acc: 0.9699\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4860 - acc: 0.9745\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4825 - acc: 0.9780\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 1.4801 - acc: 0.9811\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4777 - acc: 0.9826\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4764 - acc: 0.9840\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 1.4750 - acc: 0.9852\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5792cbad68>"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of epochs\n",
    "n_epochs = 10\n",
    "# fit the model of the training data/labels\n",
    "# verbose=1 is chosen to print a progress bar executing the algorithm\n",
    "# verbose: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "model.fit(X_train, y_train, epochs=n_epochs, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6NSsRtkb_LtE"
   },
   "source": [
    "# Test 5: Evaluating the model on some test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wCpr6DGyE28h"
   },
   "source": [
    "### Evaluating the fit of model\n",
    "\n",
    "The model's accuracy on the testing data is evaluated using `model.evaluate` to which the testing data `X_test` and true labels `y_test` are fed as arguments. The below code shows accuracy as a metric to evaluate how well the model works, and it shows that the NN model attains a very high accuracy on the testing data. The model's linear outputs are in the form of [logits](https://developers.google.com/machine-learning/glossary#logits). A `tf.keras.layers.Softmax` layer is attached to these logits in order to convert them to probabilities of the datapoint belonging to each class, and the datapoint's predicted class is selected as the class with the highest probability among all classes using `np.argmax`, and this class is assigned as the image's predicted label. The model can now make predictions on the testing data `X_test` using `keras.Model.predict` method, and we can then compare the predicted labels to the true labels `y_test`. `keras.Model.predict` returns a list of lists, where each list corresponds to one image in the batch of data. For example, the first datapoint in the testing data is shown to have matching true and predicted label in the below code.\n",
    "\n",
    "### Experiment using K-fold cross-validation\n",
    "\n",
    "K-fold cross-validation (CV) is used to test a regression or classification algorithm properly, and consists in splitting the training dataset into K-folds, training on K-1 of them and validating on the remaining fold, and switching the validation fold K times. The resulting mean cv accuracy is a less-biased metric of the performance of the algorithm on the training dataset. To create cross-validation folds, a method from `sklearn` called `sklearn.model_selection.cross_val_score` is used to split the dataset, call the neural network constructor by argument `estimator`, specify the desired number of folds by argument `cv`, specify the training data and labels by arguments `X` and `y`, and finally perform cross-validation. The K-fold cross validation choose a number of folds `cv` equal to 5, which results in an accuracy for each run of the cross validation and a mean accuracy for the total cross validation such as shown by the below code. To build the `estimator` parsed as an argument to `sklearn.model_selection.cross_val_score`, the Keras constructor `KerasClassifier` is called. It takes a building function `build_fn` that indicate how the NN model is to be built and compiled, which was implemented in the `neurnet_classifier()` method below. Since `tf.keras` models are optimized to make predictions on a `batch`, which is collection of datapoints processed by the NN at once, a `batch_size` of value 1000 is chosen; it allows processing the training data of size 60,000 faster by the NN while attaining a very good training accuracy. This experiment used cross validation to vary the parameters on the number of epochs and compare the NN's performance on the training data. The number of epochs was varied from 1 to 20, and the below plots shows that the best cross validation accuracy was achieved with `n_epochs = 20`.\n",
    "\n",
    "### Experiment using grid search cross-validation\n",
    "An experiment using grid search cross-validation results to finetune the model's parameters and improve predictions results is run. Using `sklearn.model_selection.GridSearchCV`, several grid search cross validation models are created by generating a model for each tuple of parameters' values specified in list `params`. It  calls the neural network constructor by argument `estimator`, and uses the proposed lists of values for `optimizer`, `number of epochs` and `batch_size`. The scoring metric in this experiment is the mean cv accuracy as specified by argument `scoring`. These models are then fit to the training data using `fit` method, and the best tuple of parameters among all choices is returned by `best_params_` corresponding to the best score returned by `best_score_`. In this manner, the NN model parameters are automatically finetuned and could be fit to changing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 60065,
     "status": "ok",
     "timestamp": 1585957589182,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "VflXLEeECaXC",
    "outputId": "0e19f478-eef4-4aef-9ee6-6b51f8267c72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 2ms/step - loss: 1.4864 - acc: 0.9754\n",
      "Model's testing accuracy = 97.54%\n",
      "example datapoint: true label is 7 and predicted label is 7\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model on the testing data/labels\n",
    "# verbose=1 is chosen to print a progress bar executing the algorithm\n",
    "# verbose: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "_, test_accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print('Model\\'s testing accuracy = {0:.2f}%'.format(test_accuracy * 100))\n",
    "# generate predicted output using softmax, which selects the class with highest\n",
    "# probability among all classes and assigns it as the image's predicted label\n",
    "prediction_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
    "# generate predictions for the testing data\n",
    "preds = prediction_model.predict(X_test)\n",
    "# check prediction on a datapoint\n",
    "print('example datapoint: true label is {0:d} and predicted label is {1:d}'.format(y_test[0], np.argmax(preds[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 285174,
     "status": "ok",
     "timestamp": 1585957814294,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "DumtwJZ2AzFx",
    "outputId": "4346c3d3-6492-4025-e947-f5761a423952"
   },
   "outputs": [],
   "source": [
    "# experiment using K-fold cross-validation results to choose a model parameter\n",
    "# in the below case to choose an appropriate number of epochs\n",
    "#\n",
    "def neurnet_classifier():\n",
    "    # create model with each input being flattened\n",
    "    # sequential model is used to indicate the model has a linear stack of layers\n",
    "    # flatten is used to flatten the 28x28 input to 1x784 input\n",
    "    # dense layers are used to have fully interconnected neurons, allowing faster learning\n",
    "    # the number of neurons at the output layer must be equal to the number of classes (10)\n",
    "    # the relu activation function is chosen for the hidden layer because\n",
    "    # it avoids the saturation of its gradient, thus accelerating the convergence of \n",
    "    # gradient descent compared to other activation functions such as sigmoid / tanh\n",
    "    # the sigmoid activation function is chosen to smoothen the output to nearest\n",
    "    # value of either 0 (image not in class) or 1 (image in class)\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "    ])\n",
    "    # compile model that compares performance using accuracy as a metric, \n",
    "    # an optimizer based on the gradient descent algorithm such as adam, and \n",
    "    # a sparse categorical cross entropy which computes the crossentropy loss \n",
    "    # between the predictions and true labels, and is specifically designed for \n",
    "    # multi-class problems. from_logits indicates whether the prediction is a logits tensor.\n",
    "    # Using from_logits=True is more numerically stable according to documentation.\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer='adam',\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "#\n",
    "# number of datapoints propagated through the NN to train it each time\n",
    "n_batchsz   = 1000\n",
    "# number of cross validation folds\n",
    "n_cvfolds   = 5\n",
    "# multiple values for parameter: number of epochs\n",
    "epochs_vals = range(1,21)\n",
    "# record mean cv accuracy for each parameter: number of epochs\n",
    "acc_means   = np.empty((len(epochs_vals)))\n",
    "for i in range(len(epochs_vals)):\n",
    "    n_epochs     = epochs_vals[i]\n",
    "    # construct a NN classifier using Keras constructor and calling the building function above\n",
    "    cf           = KerasClassifier(build_fn=neurnet_classifier, batch_size=n_batchsz, epochs=n_epochs)\n",
    "    # perform K-fold cross validation on training data/labels to return the list of accuracies\n",
    "    accuracies   = cross_val_score(estimator=cf, X=X_train, y=y_train, cv=n_cvfolds)\n",
    "    # cross validation (CV) mean accuracy\n",
    "    acc_means[i] = accuracies.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 285498,
     "status": "ok",
     "timestamp": 1585957814624,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "APhK0TSMuzaZ",
    "outputId": "f6a60009-3240-4254-8b11-e7cd5c88c525"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEGCAYAAAB/+QKOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqdf/B0IAiPdtFrPUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_epochs = 20 resulted in highest cv accuracy of 95.27%\n"
     ]
    }
   ],
   "source": [
    "# after cv is run iteratively on a list of values for a certain parameter, the\n",
    "# value resulting in highest mean accuracy (i.e. lowest mean error) is chosen\n",
    "# make a plot of mean cv accuracies vs number of epochs\n",
    "plt.plot(epochs_vals, acc_means)\n",
    "plt.xticks(epochs_vals)\n",
    "plt.xlabel('number of epochs')\n",
    "plt.ylabel('cross-validation accuracy (in %)')\n",
    "plt.show()\n",
    "# best value of n_epochs corresponding to highest cv accuracy (i.e. lowest cv error)\n",
    "i = int(np.argmax(acc_means))\n",
    "print('n_epochs = %d resulted in highest cv accuracy of %.2f%%' % \n",
    "      (epochs_vals[i],100*acc_means[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487524,
     "status": "ok",
     "timestamp": 1585958016657,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "4lLiVAzhBHnN",
    "outputId": "fdb5e0af-ffdf-47bb-bf50-e1f11acdf246"
   },
   "outputs": [],
   "source": [
    "# experiment using grid search cross-validation results to finetune the model's\n",
    "# parameters and improve predictions results\n",
    "#\n",
    "def neurnet_classifier(optimizer):\n",
    "    # create model with each input being flattened\n",
    "    # sequential model is used to indicate the model has a linear stack of layers\n",
    "    # flatten is used to flatten the 28x28 input to 1x784 input\n",
    "    # dense layers are used to have fully interconnected neurons, allowing faster learning\n",
    "    # the number of neurons at the output layer must be equal to the number of classes (10)\n",
    "    # the relu activation function is chosen for the hidden layer because\n",
    "    # it avoids the saturation of its gradient, thus accelerating the convergence of \n",
    "    # gradient descent compared to other activation functions such as sigmoid / tanh\n",
    "    # the sigmoid activation function is chosen to smoothen the output to nearest\n",
    "    # value of either 0 (image not in class) or 1 (image in class)\n",
    "    model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dense(10, activation='sigmoid')\n",
    "    ])\n",
    "    # compile model that compares performance using accuracy as a metric, \n",
    "    # an optimizer based on the gradient descent algorithm such as adam, and \n",
    "    # a sparse categorical cross entropy which computes the crossentropy loss \n",
    "    # between the predictions and true labels, and is specifically designed for \n",
    "    # multi-class problems. from_logits indicates whether the prediction is a logits tensor.\n",
    "    # Using from_logits=True is more numerically stable according to documentation.\n",
    "    model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['acc'])\n",
    "    return model\n",
    "#\n",
    "# construct a NN classifier using Keras constructor and calling the building function above\n",
    "cf = KerasClassifier(build_fn=neurnet_classifier)\n",
    "# list of values for multiple parameters in the model to be fed to grid search cv\n",
    "optimizers = ['adadelta', 'adam', 'rmsprop', 'sgd']\n",
    "n_epochs   = [10, 20]\n",
    "n_batchsz  = [1000, 5000]\n",
    "params     = {\n",
    "    'optimizer' : optimizers,\n",
    "    'epochs'    : n_epochs,\n",
    "    'batch_size': n_batchsz}\n",
    "# create grid seach cross validation models by generating a model for each tuple of \n",
    "# parameters' values specified by params. Scoring metric is the mean cv accuracy\n",
    "n_cvfolds  = 5\n",
    "gscv       = GridSearchCV(\n",
    "    estimator  = cf,\n",
    "    param_grid = params,\n",
    "    cv         = n_cvfolds,\n",
    "    scoring    = 'accuracy'\n",
    "    )\n",
    "# fit the set of models to the training data/labels\n",
    "# verbose=1 is chosen to print a progress bar executing the algorithm\n",
    "# verbose: 0 = silent, 1 = progress bar, 2 = one line per epoch\n",
    "gscv       = gscv.fit(X_train, y_train, verbose=1)\n",
    "# use best_params_ method to return the tuple of parameters that resulted in\n",
    "# highest mean cv accuracy\n",
    "best_param = gscv.best_params_\n",
    "# corresponding mean cv accuracy\n",
    "best_acc   = gscv.best_score_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 487518,
     "status": "ok",
     "timestamp": 1585958016657,
     "user": {
      "displayName": "Mohamed Ait Mhamed Belcaid",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14Gj3YniscJ4BUeKN4EKFcU5pm_IUZqkpUZDbGlgINA=s64",
      "userId": "01130297007541980381"
     },
     "user_tz": 240
    },
    "id": "pfWtKB1DSZEO",
    "outputId": "49b7a615-6f43-4863-a301-1badaf265387"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model parameters: {'batch_size': 1000, 'epochs': 20, 'optimizer': 'rmsprop'}\n",
      "with highest cv accuracy: 95.97%\n"
     ]
    }
   ],
   "source": [
    "# show the best tuples of parameters and the corresponding mean cv accuracy\n",
    "print('best model parameters:', best_param)\n",
    "print('with highest cv accuracy: %.2f%%' % (100*best_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TF_Keras_classification.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/tensorflow/docs/blob/master/site/en/tutorials/keras/classification.ipynb",
     "timestamp": 1585152136000
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
